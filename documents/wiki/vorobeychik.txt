adversarial machine learning research field lies intersection machine learning computer security aims enable safe adoption machine learning techniques adversarial settings like spam filtering malware detection biometric recognition problem arises fact machine learning techniques originally designed stationary environments training test data assumed generated although possibly unknown distribution presence intelligent adaptive adversaries however working hypothesis likely violated least degree depending adversary fact malicious adversary carefully manipulate input data exploiting specific vulnerabilities learning algorithms compromise whole system security examples include attacks spam filtering spam messages obfuscated misspelling bad words insertion good words attacks computer security e g obfuscate malware code within network packets mislead signature detection attacks biometric recognition fake biometric traits may exploited impersonate legitimate user biometric spoofing compromise users template galleries adaptively updated time